{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBAz69diMqRl",
        "outputId": "d55d1c29-415f-4dc9-c706-0f0f08ec09cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting txtai\n",
            "  Downloading txtai-5.4.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-cpu>=1.7.1.post2\n",
            "  Downloading faiss_cpu-1.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers>=4.22.0\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.9/dist-packages (from txtai) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from txtai) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy>=1.18.4 in /usr/local/lib/python3.9/dist-packages (from txtai) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->txtai) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.22.0->txtai) (3.10.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.22.0->txtai) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers>=4.22.0->txtai) (2.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.22.0->txtai) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.22.0->txtai) (23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.22.0->txtai) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.22.0->txtai) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.22.0->txtai) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.22.0->txtai) (3.4)\n",
            "Installing collected packages: tokenizers, faiss-cpu, huggingface-hub, transformers, txtai\n",
            "Successfully installed faiss-cpu-1.7.3 huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.4 txtai-5.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install txtai\n",
        "!pip install\n",
        "\n",
        "import constants\n",
        "import requests\n",
        "import json\n",
        "from txtai.embeddings import Embeddings\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getAuthContent():\n",
        "    \"\"\" Retrieve info needed to authorize TFS API endpoint call\n",
        "        auth_content should have 'access_token' and 'instance_url' fields at minimum, otherwise None is returned.\n",
        "    \"\"\"\n",
        "    # Make authentication call\n",
        "    auth_res = requests.post(constants.AUTH_CALLBACK_URL,\n",
        "                             params={\n",
        "                                 'grant_type': 'password',\n",
        "                                 'client_id': constants.AUTH_CONSUMER_KEY,\n",
        "                                 'client_secret': constants.AUTH_CONSUMER_SECRET,\n",
        "                                 'username': constants.AUTH_USER,\n",
        "                                 'password': constants.AUTH_PASS\n",
        "                             }\n",
        "                             )\n",
        "    # Check if Auth response was successful or not\n",
        "    if auth_res.status_code != 200 or \"application/json\" not in auth_res.headers.get(\"Content-Type\"):\n",
        "        return None\n",
        "    auth_content = json.loads(auth_res.content)\n",
        "    if auth_content.get(\"access_token\") is None or auth_content.get(\"instance_url\") is None:\n",
        "        return None\n",
        "\n",
        "    return auth_content"
      ],
      "metadata": {
        "id": "YZP6qreAMzom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getAPIContent(auth_content, query):\n",
        "    \"\"\" Get APIs from TFS API Portal endpoint for the given query.\n",
        "        auth_content should have 'access_token' and 'instane_url' fields \"\"\"\n",
        "    access_token = auth_content[\"access_token\"]\n",
        "    instance_url = auth_content[\"instance_url\"]\n",
        "    # Make call to get APIs from TFS endpoint\n",
        "    api_res = requests.get(instance_url + constants.TFS_API_ENDPOINT,\n",
        "                           params={'q': query},\n",
        "                           headers={'Authorization': \"Bearer \" + access_token}\n",
        "                           )\n",
        "    if api_res.status_code != 200 or \"application/json\" not in api_res.headers.get(\"Content-Type\"):\n",
        "        return None\n",
        "    api_content = json.loads(api_res.content)\n",
        "    return api_content"
      ],
      "metadata": {
        "id": "R7etjqjNM3CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apiToPlainText(api):\n",
        "    \"\"\" api must be a SObject of type acm_pkg__CommunityApi__c \"\"\"\n",
        "    name = api[constants.API_NAME]\n",
        "    description = api[constants.API_DESC]\n",
        "    if description is None:\n",
        "        return name, name\n",
        "    return name, description"
      ],
      "metadata": {
        "id": "NYqZ7w2OM43B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auth_content = getAuthContent()\n",
        "api_content = getAPIContent(auth_content, constants.API_QUERY_UTDPORTAL)\n",
        "data = api_content['records']\n",
        "response = []\n",
        "\n",
        "for api in data:\n",
        "    name, desc, id = apiToPlainText(api)\n",
        "    response.append([name, desc, id])\n",
        "df = pd.DataFrame(response)\n",
        "df.columns = ['Name', 'Description', 'Id']\n",
        "df.drop_duplicates(subset=['Name'], inplace=True)\n",
        "embeddings = Embeddings({\"path\": \"sentence-transformers/nli-mpnet-base-v2\", \"content\": True})\n",
        "embeddings.index([(uid, text, None) for uid, text in enumerate(df['Description'])])\n",
        "embeddings.save('newModel')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xKbUnsgM7BI",
        "outputId": "484f164d-9609-4785-bde5-f6c5044bf4c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': '11',\n",
              "  'text': 'This API sends customer Activity and Case information to BI (Business Intelligence) system for reports.',\n",
              "  'score': 0.5227376818656921},\n",
              " {'id': '21',\n",
              "  'text': 'SFMC Transactional Email & SMS API provides functionality for sending Low Latency Email and SMS to individuals or groups of contacts.',\n",
              "  'score': 0.46152830123901367},\n",
              " {'id': '29',\n",
              "  'text': 'The operation purpose of this service is to provide Data Market Place and other domains an access to consume AXON related facets and information that can be leveraged in their development process.',\n",
              "  'score': 0.42580646276474}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.save('/content/index')"
      ],
      "metadata": {
        "id": "DCzhy5C3UrU2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}